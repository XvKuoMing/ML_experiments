{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Цель\n",
        "Написать трансформер с нуля для перевода с английского на русский\n"
      ],
      "metadata": {
        "id": "afuULpUTGyLt"
      },
      "id": "afuULpUTGyLt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "f4uB69YwSJH1"
      },
      "id": "f4uB69YwSJH1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3b0ea3c",
      "metadata": {
        "id": "e3b0ea3c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# !apt-get install unzip\n",
        "# !pip install nltk\n",
        "!pip install keras --upgrade\n",
        "!pip install tokenizers\n",
        "!pip install torch==2.0.1\n",
        "!pip install tokenizers matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9220b9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9220b9d",
        "outputId": "1b98a7b1-9695-44cd-eafb-379a9a924cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keras.__version__ = '3.1.1'\n",
            "torch.__version__ = '2.0.1+cu117'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import keras\n",
        "import torch\n",
        "print(f\"{keras.__version__ = }\")\n",
        "print(f\"{torch.__version__ = }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "947b3313",
      "metadata": {
        "id": "947b3313"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordPiece\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers import normalizers\n",
        "from tokenizers.normalizers import Lowercase\n",
        "from tokenizers.trainers import WordPieceTrainer\n",
        "from tokenizers import decoders\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##preparation"
      ],
      "metadata": {
        "id": "TKNsYSjzRiQj"
      },
      "id": "TKNsYSjzRiQj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kvUX7tdtc5pZ",
      "metadata": {
        "id": "kvUX7tdtc5pZ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38911d06",
      "metadata": {
        "id": "38911d06"
      },
      "outputs": [],
      "source": [
        "text = open('opus.en-ru-train.ru').read().replace('\\xa0', ' ')\n",
        "f = open('opus.en-ru-train.ru', 'w')\n",
        "f.write(text)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e110ff04",
      "metadata": {
        "id": "e110ff04"
      },
      "outputs": [],
      "source": [
        "en_sents = open('opus.en-ru-train.en').read().lower().splitlines()\n",
        "ru_sents = open('opus.en-ru-train.ru').read().lower().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0be060a4",
      "metadata": {
        "id": "0be060a4"
      },
      "outputs": [],
      "source": [
        "tokenizer_en = Tokenizer(WordPiece(), )\n",
        "tokenizer_en.normalizer = normalizers.Sequence([Lowercase()])\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_en = WordPieceTrainer(\n",
        "          vocab_size=30000, special_tokens=[\"[UNK]\", \"[PAD]\"])\n",
        "tokenizer_en.train(files=[\"opus.en-ru-train.en\"], trainer=trainer_en )\n",
        "\n",
        "tokenizer_ru = Tokenizer(WordPiece(), )\n",
        "tokenizer_ru.normalizer = normalizers.Sequence([Lowercase()])\n",
        "tokenizer_ru.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_ru = WordPieceTrainer(\n",
        "          vocab_size=30000, special_tokens=[\"[UNK]\", \"[PAD]\", \"[START]\", \"[END]\", ])\n",
        "tokenizer_ru.train(files=[\"opus.en-ru-train.ru\"], trainer=trainer_ru )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xWX3xnMUzbdt",
      "metadata": {
        "id": "xWX3xnMUzbdt"
      },
      "outputs": [],
      "source": [
        "tokenizer_en.decoder = decoders.WordPiece()\n",
        "tokenizer_ru.decoder = decoders.WordPiece()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "496d0ea7",
      "metadata": {
        "id": "496d0ea7"
      },
      "outputs": [],
      "source": [
        "tokenizer_en.save('tokenizer_en')\n",
        "tokenizer_ru.save('tokenizer_ru')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4661964",
      "metadata": {
        "id": "f4661964"
      },
      "outputs": [],
      "source": [
        "tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n",
        "tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc003758",
      "metadata": {
        "id": "dc003758"
      },
      "outputs": [],
      "source": [
        "def encode(text, tokenizer, target=False):\n",
        "    if target:\n",
        "        return [tokenizer.token_to_id('[START]')] + tokenizer.encode(text).ids + \\\n",
        "                [tokenizer.token_to_id('[END]')]\n",
        "    else:\n",
        "        return tokenizer.encode(text).ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc2dae1",
      "metadata": {
        "id": "7fc2dae1"
      },
      "outputs": [],
      "source": [
        "X_en = [encode(t, tokenizer_en) for t in en_sents]\n",
        "X_ru = [encode(t, tokenizer_ru, True) for t in ru_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "281b5b90",
      "metadata": {
        "id": "281b5b90"
      },
      "outputs": [],
      "source": [
        "max_len_en = np.max([len(x) for x in X_en])\n",
        "max_len_ru = np.max([len(x) for x in X_ru])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5984886a",
      "metadata": {
        "id": "5984886a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5625c9cf-23c5-4f65-acaf-3cdbffb5fad5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17863, 19389)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "max_len_en, max_len_ru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc0a376",
      "metadata": {
        "id": "5cc0a376"
      },
      "outputs": [],
      "source": [
        "# обратите внимание, что в seq2seq длины могут быть разными\n",
        "max_len_en = int(np.percentile([len(x) for x in X_en], 95))\n",
        "max_len_ru = int(np.percentile([len(x) for x in X_ru], 95))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f4f31fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f4f31fa",
        "outputId": "b9fa1aa3-759f-479d-dd45-5eef0627d334"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
        "PAD_IDX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ae735e",
      "metadata": {
        "id": "49ae735e"
      },
      "outputs": [],
      "source": [
        "X_en = keras.preprocessing.sequence.pad_sequences(\n",
        "              X_en, maxlen=max_len_en, padding='post', value=PAD_IDX)\n",
        "\n",
        "X_ru_out = keras.preprocessing.sequence.pad_sequences(\n",
        "              [x[1:] for x in X_ru], maxlen=max_len_ru-1, padding='post',\n",
        "              value=PAD_IDX)\n",
        "\n",
        "X_ru_dec = keras.preprocessing.sequence.pad_sequences(\n",
        "              [x[:-1] for x in X_ru], maxlen=max_len_ru-1,\n",
        "              padding='post', value=PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "824dcb29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "824dcb29",
        "outputId": "48509ec0-c964-4193-8ba1-18f76d44dba3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000000, 45), (1000000, 47))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_en.shape, X_ru_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25fa5f05",
      "metadata": {
        "id": "25fa5f05"
      },
      "outputs": [],
      "source": [
        "(X_en_train, X_en_valid,\n",
        "X_ru_dec_train, X_ru_dec_valid,\n",
        "X_ru_out_train, X_ru_out_valid) = train_test_split(X_en,\n",
        "                                                  X_ru_dec,\n",
        "                                                  X_ru_out,\n",
        "                                                  test_size=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##transformer code"
      ],
      "metadata": {
        "id": "ODQFC6R2RV7O"
      },
      "id": "ODQFC6R2RV7O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "656be820",
      "metadata": {
        "id": "656be820"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    # Считаем скалярное произведение между запросом (query) и ключом (key), транспонируя ключ\n",
        "    matmul_qk = keras.ops.matmul(query, keras.ops.transpose(key, axes=[0, 1, 3, 2]))\n",
        "\n",
        "    # Получаем глубину (размерность) ключа и преобразуем ее во float\n",
        "    depth = keras.ops.cast(key.shape[-1], torch.float32)\n",
        "\n",
        "    # Делим результат скалярного произведения на квадратный корень из глубины\n",
        "    # Это делается для уменьшения влияния больших значений и стабилизации градиентов во время обучения\n",
        "    logits = matmul_qk / keras.ops.sqrt(depth)\n",
        "\n",
        "    # Если есть маска, применяем ее к логитам, чтобы обнулить нежелательные значения\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # Применяем функцию softmax для получения весов внимания\n",
        "    attention_weights = keras.ops.softmax(logits, axis=-1)\n",
        "\n",
        "    # Умножаем веса внимания на значения (value) для получения итогового результата\n",
        "    output = keras.ops.matmul(attention_weights, value)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b51870",
      "metadata": {
        "id": "f4b51870"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads  # количество голов для внимания\n",
        "        self.d_model = d_model  # размерность вектора модели\n",
        "\n",
        "        # Убеждаемся, что размерность модели делится нацело на количество голов\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads  # размерность каждой головы\n",
        "\n",
        "        # Создаем полносвязные слои для запроса, ключа и значения\n",
        "        self.query_dense = keras.layers.Dense(units=d_model)\n",
        "        self.key_dense = keras.layers.Dense(units=d_model)\n",
        "        self.value_dense = keras.layers.Dense(units=d_model)\n",
        "\n",
        "        # Создаем последний полносвязный слой\n",
        "        self.dense = keras.layers.Dense(units=d_model)\n",
        "\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        # Разделяем входные данные на головы\n",
        "        inputs = keras.ops.reshape(\n",
        "            inputs, newshape=(batch_size, -1, self.num_heads, self.depth))\n",
        "        return keras.ops.transpose(inputs, axes=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "            'value'], inputs.get('mask', None)\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # Пропускаем запрос, ключ и значение через соответствующие полносвязные слои\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        # Разделяем запрос, ключ и значение на головы\n",
        "        # то есть просто разрезаем вектора на num_heads частей\n",
        "        # и сравниваем все части между собой\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # Выполняем механизм внимания с масштабированным скалярным произведением\n",
        "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "        scaled_attention = keras.ops.transpose(scaled_attention, axes=[0, 2, 1, 3])\n",
        "\n",
        "        # Объединяем головы вместе (склеиваем векторы в один)\n",
        "        concat_attention = keras.ops.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))\n",
        "\n",
        "        # Пропускаем объединенное внимание через дополнительный полносвязный слой\n",
        "        # Он просто добавляет сложности нашей модели\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c48cea2",
      "metadata": {
        "id": "5c48cea2"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(x):\n",
        "    mask = keras.ops.cast(keras.ops.equal(x, PAD_IDX), torch.float32)\n",
        "    # (batch_size, 1, 1, sequence length)\n",
        "    return mask[:, None, None, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c0c899",
      "metadata": {
        "id": "21c0c899"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    # эта функция немножко сложная, но суть у нее достаточно простая\n",
        "    # нужно создать треугольную маску, с помощью которой мы закроем\n",
        "    # для каждого токена все последующие токены\n",
        "    seq_len = x.shape[1]\n",
        "    ones_mask = keras.ops.ones((1, seq_len, seq_len), dtype=\"int32\")\n",
        "    row_index = keras.ops.cumsum(ones_mask, axis=-2)\n",
        "    col_index = keras.ops.cumsum(ones_mask, axis=-1)\n",
        "    look_ahead_mask = ~ keras.ops.greater_equal(row_index, col_index)\n",
        "    padding_mask = create_padding_mask(x)\n",
        "    return keras.ops.maximum(look_ahead_mask, padding_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e120bbe5",
      "metadata": {
        "id": "e120bbe5"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / keras.ops.power(10000, (2 * (i // 2)) / d_model)\n",
        "        return keras.ops.multiply(position, angles)\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "            position=torch.arange(0, position, dtype=torch.float32)[:, None],\n",
        "            i=torch.arange(0, d_model, dtype=torch.float32)[None, :],\n",
        "            d_model=d_model)\n",
        "        sines = keras.ops.sin(angle_rads[:, 0::2])\n",
        "        cosines = keras.ops.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = keras.ops.concatenate([sines, cosines], axis=-1)\n",
        "        pos_encoding = pos_encoding[None, ...]\n",
        "        return keras.ops.cast(pos_encoding, torch.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :inputs.shape[1], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68472627",
      "metadata": {
        "id": "68472627"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    padding_mask = keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    #call_mha\n",
        "    attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "    attention = keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    outputs = keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "    outputs = keras.layers.Dense(units=d_model)(outputs)\n",
        "    outputs = keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "    return keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89dcc42e",
      "metadata": {
        "id": "89dcc42e"
      },
      "outputs": [],
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            max_len,\n",
        "            name=\"encoder\"):\n",
        "    inputs = keras.Input(shape=(max_len,), name=\"inputs\")\n",
        "    padding_mask = keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    embeddings = keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= keras.ops.sqrt(keras.ops.cast(d_model, torch.float32))\n",
        "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
        "\n",
        "    #inputs (они тут называются outputs но это просто такой нейминг,\n",
        "    # этот параметр передается в encoder_layer первым и encoder_layer будет считать его inputs)\n",
        "    # outputs он тут называется для удобства, так как он будет перезаписываться\n",
        "    # чтобы на вход следующему блоку подавать уже не эмбединги,\n",
        "    # а то что получится как результат предыдущего блока\n",
        "    outputs = keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name=\"encoder_layer_{}\".format(i),\n",
        "        )([outputs, padding_mask])\n",
        "\n",
        "    return keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2f90e7c",
      "metadata": {
        "id": "a2f90e7c"
      },
      "outputs": [],
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "    inputs = keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    enc_outputs = keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "    look_ahead_mask = keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "    padding_mask = keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "    attention1 = keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "    attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "    attention2 = keras.layers.Dropout(rate=dropout)(attention2)\n",
        "    attention2 = keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "    outputs = keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "    outputs = keras.layers.Dense(units=d_model)(outputs)\n",
        "    outputs = keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "    return keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c0dd6a2",
      "metadata": {
        "id": "1c0dd6a2"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            max_len,\n",
        "            name='decoder'):\n",
        "    inputs = keras.Input(shape=(max_len,), name='inputs')\n",
        "    enc_outputs = keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "    look_ahead_mask = keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "    padding_mask = keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    embeddings = keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= keras.ops.sqrt(keras.ops.cast(d_model, torch.float32))\n",
        "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
        "\n",
        "    outputs = keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name='decoder_layer_{}'.format(i),\n",
        "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "    return keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e356741b",
      "metadata": {
        "id": "e356741b"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                max_len,\n",
        "                name=\"transformer\"):\n",
        "    inputs = keras.Input(shape=(max_len[0],), name=\"inputs\")\n",
        "    dec_inputs = keras.Input(shape=(max_len[1]-1,), name=\"dec_inputs\")\n",
        "\n",
        "    enc_padding_mask = keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "    look_ahead_mask = keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "    dec_padding_mask = keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "    enc_outputs = encoder(\n",
        "                          vocab_size=vocab_size[0],\n",
        "                          num_layers=num_layers,\n",
        "                          units=units,\n",
        "                          d_model=d_model,\n",
        "                          num_heads=num_heads,\n",
        "                          dropout=dropout,\n",
        "                          max_len=max_len[0],\n",
        "                        )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "    dec_outputs = decoder(\n",
        "                          vocab_size=vocab_size[1],\n",
        "                          num_layers=num_layers,\n",
        "                          units=units,\n",
        "                          d_model=d_model,\n",
        "                          num_heads=num_heads,\n",
        "                          dropout=dropout,\n",
        "                          max_len=max_len[1]-1,\n",
        "                        )(inputs=[dec_inputs, enc_outputs,\n",
        "                                  look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    outputs = keras.layers.Dense(units=vocab_size[1], name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d23ece2d",
      "metadata": {
        "id": "d23ece2d"
      },
      "outputs": [],
      "source": [
        "L  = keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none',)\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "    loss = L(y_true, y_pred)\n",
        "\n",
        "    mask = keras.ops.cast(keras.ops.not_equal(y_true, PAD_IDX), torch.float32)\n",
        "    loss = keras.ops.multiply(loss, mask)\n",
        "\n",
        "    return keras.ops.mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##training"
      ],
      "metadata": {
        "id": "qZIT2qMSRcPC"
      },
      "id": "qZIT2qMSRcPC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "542fcc43",
      "metadata": {
        "id": "542fcc43"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "# small model\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "\n",
        "# average model\n",
        "# NUM_LAYERS = 6\n",
        "# D_MODEL = 512\n",
        "# NUM_HEADS = 8\n",
        "# UNITS = 2048\n",
        "# DROPOUT = 0.1\n",
        "\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=(tokenizer_en.get_vocab_size(),tokenizer_ru.get_vocab_size()),\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT,\n",
        "    max_len=[max_len_en, max_len_ru])\n",
        "\n",
        "\n",
        "optimizer = keras.optimizers.Adam(\n",
        "    0.001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('model_ruen.weights.h5',\n",
        "                                            monitor='val_loss',\n",
        "                                            verbose=1,\n",
        "                                            save_weights_only=True,\n",
        "                                            save_best_only=True,\n",
        "                                            mode='min',\n",
        "                                            save_freq='epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "439f7e12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "439f7e12",
        "outputId": "e05f7e8f-4a44-47d1-d655-d13f36656ed1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2673cd",
      "metadata": {
        "id": "1b2673cd"
      },
      "outputs": [],
      "source": [
        "# model.load_weights('model_ruen.weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "308a8e81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "308a8e81",
        "outputId": "c92a483a-7532-49f3-e68d-763bdcecc1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4750/4750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.0904 - loss: 1.6003\n",
            "Epoch 1: val_loss improved from inf to 0.99517, saving model to model_ruen.weights.h5\n",
            "\u001b[1m4750/4750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1682s\u001b[0m 354ms/step - accuracy: 0.0904 - loss: 1.6003 - val_accuracy: 0.1474 - val_loss: 0.9952\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fe53fe3f2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model.fit((X_en_train, X_ru_dec_train), X_ru_out_train,\n",
        "             validation_data=((X_en_valid, X_ru_dec_valid), X_ru_out_valid),\n",
        "             batch_size=200,\n",
        "             epochs=1,\n",
        "             callbacks=[checkpoint]\n",
        "             )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## translation"
      ],
      "metadata": {
        "id": "sEaep1SeRn4k"
      },
      "id": "sEaep1SeRn4k"
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def translate_optim(texts: list): # я попытался оптимизировать, но так и не понял как генерировать несколько предложений\n",
        "\n",
        "    input_ids = []\n",
        "\n",
        "    for text in texts: # закодируем каждый текст\n",
        "      input_ids.append(\n",
        "          encode(text, tokenizer_en, target=False)\n",
        "      )\n",
        "\n",
        "    input_ids = keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "                                      [input_ids], maxlen=max_len_en, padding='post',\n",
        "                                       # важно не забыть паддинг с нужным id\n",
        "                                       value=PAD_IDX), torch.int32)\n",
        "\n",
        "\n",
        "\n",
        "    output_ids = [tokenizer_ru.token_to_id('[START]') ]\n",
        "\n",
        "    preds = model((input_ids, keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "                                      [output_ids], maxlen=max_len_ru-1, padding='post',\n",
        "                                       # важно не забыть паддинг с нужным id\n",
        "                                       value=PAD_IDX), torch.int32))).cpu().numpy()\n",
        "\n",
        "\n",
        "    translated = []\n",
        "\n",
        "    while True:\n",
        "        if len(output_ids) >= max_len_ru:\n",
        "          break\n",
        "        # можно занизить скор тэга UNK чтобы он никогда не генерировался\n",
        "        preds[:, :, tokenizer_ru.token_to_id('[UNK]')] = -100\n",
        "\n",
        "        output_ids.append(preds.argmax(2)[0][-1])\n",
        "        preds = model((input_ids, keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "                                      [output_ids], maxlen=max_len_ru-1, padding='post',\n",
        "                                       # важно не забыть паддинг с нужным id\n",
        "                                       value=PAD_IDX), torch.int32))).cpu().numpy()\n",
        "\n",
        "    translated.append(tokenizer_ru.decode(output_ids[1:],))\n",
        "\n",
        "    return translated\n"
      ],
      "metadata": {
        "id": "FVhh6FQyt2_D"
      },
      "id": "FVhh6FQyt2_D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63762869",
      "metadata": {
        "id": "63762869"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def translate(text):\n",
        "    input_ids = encode(text, tokenizer_en, target=False)\n",
        "    input_ids = keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "                                      [input_ids], maxlen=max_len_en, padding='post',\n",
        "                                       # важно не забыть паддинг с нужным id\n",
        "                                       value=PAD_IDX), torch.int32)\n",
        "\n",
        "\n",
        "    output_ids = [tokenizer_ru.token_to_id('[START]') ]\n",
        "\n",
        "    pred = model((input_ids, keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "                                      [output_ids], maxlen=max_len_ru-1, padding='post',\n",
        "                                       # важно не забыть паддинг с нужным id\n",
        "                                       value=PAD_IDX), torch.int32))).cpu().numpy()\n",
        "\n",
        "    while pred.argmax(2)[0][-1] not in [tokenizer_ru.token_to_id('[END]')]:\n",
        "        if len(output_ids) >= max_len_ru:\n",
        "            break\n",
        "        # можно занизить скор тэга UNK чтобы он никогда не генерировался\n",
        "        pred[:, :, tokenizer_ru.token_to_id('[UNK]')] = -100\n",
        "\n",
        "        output_ids.append(pred.argmax(2)[0][-1])\n",
        "        pred = model((input_ids, keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "                                      [output_ids], maxlen=max_len_ru-1, padding='post',\n",
        "                                       # важно не забыть паддинг с нужным id\n",
        "                                       value=PAD_IDX), torch.int32))).cpu().numpy()\n",
        "\n",
        "    return tokenizer_ru.decode(output_ids[1:], )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f16e8b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5f16e8b5",
        "outputId": "4a79a546-c1e5-49b4-fd65-85880d3415d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mod'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "translate(\"Transformer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0ee1b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7d0ee1b8",
        "outputId": "acca3764-11a2-4ef8-84f4-0e98543ccb6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'можете перевести это??'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "translate(\"can you translate this sentence?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0b57d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aa0b57d2",
        "outputId": "de381d59-e88d-4ed2-94a5-489707692348"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'пожалуйста перевести эту эту предложение в предложение'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "translate(\"please translate this sentence into russian\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "TKNsYSjzRiQj",
        "ODQFC6R2RV7O"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}